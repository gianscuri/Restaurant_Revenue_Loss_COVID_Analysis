---
title: "Random Forest - Ristorante 1"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '5'
  beamer_presentation:
    colortheme: lily
    fig_caption: no
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    theme: Hannover
    toc: yes
  prettydoc::html_pretty:
    df_print: paged
    highlight: vignette
    theme: architect
    toc: yes
    toc_depth: 5
  pdf_document:
    toc: yes
    toc_depth: 5
  slidy_presentation:
    highlight: default
  ioslides_presentation:
    css:
    - css/fonts.css
    - css/custom.css
    - css/title-slide.css
    - css/slide-background.css
    includes:
      before_body: html/TimeSeriesAnalysis.html
    toc: yes
    transition: default
    widescreen: yes
course: Progetto Data Science Lab
---

# Setup

```{r}
# Clean Workspace
rm(list=ls())
```

```{r setup, include=FALSE}
# Use 'verbatim = TRUE' as chunk option to show chunk code as is
require(knitr)
hook_source_def = knit_hooks$get('source')
knit_hooks$set(source = function(x, options){
  if (!is.null(options$verbatim) && options$verbatim){
    opts = gsub(",\\s*verbatim\\s*=\\s*TRUE\\s*", "", options$params.src)
    bef = sprintf('\n\n    ```{r %s}\n', opts, "\n")
    stringr::str_c(bef, paste(knitr:::indent_block(x, "    "), collapse = '\n'), "\n    ```\n")
  } else {
     hook_source_def(x, options)
  }
})
```

```{r}
set.seed(100)

# Setting librerie utili
# Package names
packages <- c("readxl",  "readr", "forecast", "dplyr", "ggplot2",
              "lubridate", "KFAS", "tseries", "xts", "randomForest", "imputeTS") 

# Install packages if not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))


# Setting working directory
# working_dir = "C:/Users/marco/OneDrive/UNIMIB_DataScience/99-PROJECTS/DataScienceLab2022/Dati ristoranti"
# setwd(working_dir)

# MAPE 
mape <- function(actual,pred){
  mape <- mean(abs((actual - pred)/actual))*100
  return (mape)
}

#MSE
rmse <- function(actual, pred){
  rmse <- sqrt(mean((actual - pred)^2))
  return (rmse)
}

# Significatività dei parametri
pars_test <- function(coef, var_coef){
  test <- (1-pnorm(abs(coef)/sqrt(diag(var_coef))))*2
  return(test)
}

# Grafico errore percentuale 
err_plot <- function(actual, pred){
  require(xts)
  err_perc <- ((actual - xts(pred, order.by = index(actual)))/(xts(actual, order.by = index(actual))))*100
  return(plot(err_perc, ylab="% errore", main="Errore percentuale di previsione"))

}
```


```{r}
working_dir = dirname(rstudioapi::getSourceEditorContext()$path)
setwd(working_dir) # lo applica solo a questo chunk!
```

# Load Data

```{r}
postcovid1 <- read.csv("../Dati ristoranti/post-covid_r1.csv", row.names = 1)
postcovid1$lordototale[postcovid1$lordototale == 0] <- NA 
postcovid1$lordototale <- na_kalman(postcovid1$lordototale)
postcovid1 <- head(postcovid1, - 2) # Rimuovo le ultime due righe che non hanno il dato del lordo  
fest_post <- read_xlsx("../Dati aggiuntivi/fest_postcovid.xlsx")
```

# MODELLO 1 - SOLO RITARDI

```{r}
r1_post <- xts(postcovid1[, "lordototale"], as.Date(as.character(postcovid1$data), format = "%Y-%m-%d"))
```

```{r}
#train_test_split <- nrow(r1_post)*0.8
#train_test_split <- 662
```

```{r}
train1_post <- r1_post[1:train_test_split, ]
test1_post <- r1_post[-c(1:train_test_split), ]
```


```{r}
# Matrice dei ritardi

Y <- embed(train1_post, 15) # numero di ritardi + 1 che vogliamo considerare
colnames(Y) <- c("y", paste0("y_", 1:14))
```

```{r}
# Train modello

mod1_ritardi <- randomForest(y~., data = Y)
print(mod1_ritardi)
```

```{r}
# Previsioni

y_hat <- numeric(nrow(test1_post))

X <- Y[nrow(Y), -15, drop = FALSE]
colnames(X) <- colnames(Y)[-1]

for (h in 1:nrow(test1_post)) {
  y_hat[h] <- predict(mod1_ritardi, X, predict.all = TRUE)$individual |> median()
  X[1, 2:14] <- X[1, 1:13]
  X[1, 1] <- y_hat[h]
}

pred_mod1 <- as.xts(y_hat, order.by = date(test1_post))
```

```{r}
# Confronto

plot(test1_post, type = "l")
lines(pred_mod1, type = "l", col = "red")
```

```{r}
mape(test1_post, pred_mod1)
rmse(test1_post, pred_mod1)
```

# MODELLO 2 - RITARDI + WDAY + YDAY + PIOGGIA + COLORE COVID + FESTIVITA' (1 SOLA DUMMY PER TUTTE LE FESTIVITA')

```{r}
# Tengo Pioggia, Colore Covid e Festivo come regressori

r1_post2 <- xts(postcovid1[, c("lordototale", "Festivo", "Pioggia", "ColoreCOVID")], as.Date(as.character(postcovid1$data), format = "%Y-%m-%d"))

# Imputazione 
r1_post2$Festivo[r1_post2$Festivo=="False"] <- 0
r1_post2$Festivo[r1_post2$Festivo=="True"] <- 1

r1_post2$Pioggia[r1_post2$Pioggia==""] <- 0
r1_post2$Pioggia[r1_post2$Pioggia=="True"] <- 1

r1_post2$ColoreCOVID[r1_post2$ColoreCOVID == ""] <- "nessuno"
r1_post2 <- fastDummies::dummy_cols(r1_post2, select_columns = "ColoreCOVID", remove_most_frequent_dummy = TRUE, remove_selected_columns = TRUE)

# Dummy chiusura
# r1_post2$lordototale <- as.numeric(r1_post2$lordototale) # Converto a numeric per facilitare la creazione della dummy
# r1_post2 <- r1_post2 %>% 
  # mutate(Chiuso = if_else(r1_post2$lordototale == 0, 1, 0)) 

r1_post2 <- as.xts(r1_post2[-1], as.Date(r1_post2$index)) # r1_post2[-1] per rimuovere colonna index
```

```{r}
# Costruisco wday e yday

yday <- yday(time(r1_post2))
wday <- wday(time(r1_post2), week_start = getOption("lubridate.week.start", 1))
r1_post2 <- cbind(r1_post2, yday, wday)
```

```{r}
train_ndx <- 1:(train_test_split-14)
test_ndx <- (tail(train_ndx, n=1)+1):(nrow(r1_post2)-14)

#Matrice dei ritardi

X2 <- embed(r1_post2$lordototale, 15)

# Estraggo y, variabile target

y2 <- X2[, 1] 

# Attacco la matrice dei ritardi agli altri regressori

X2 <- cbind(X2[, -1], r1_post2[-(1:14), c("Festivo","Pioggia","yday","wday","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno",
                                          "ColoreCOVID_rosso")]) # ,"Chiuso" nel caso si aggiunga regressore

# Split training-test

y_train2_post <- y2[train_ndx]
X_train2_post <- X2[train_ndx, ]

y_test2_post <- y2[test_ndx]
X_test2_post <- X2[test_ndx,]

# Addestramento modello

mod2_rit_regr <- randomForest(X_train2_post, y_train2_post,
                    xtest = X_test2_post,
                    ytest = y_test2_post)

pred_mod2 <- mod2_rit_regr$test$predicted
pred_mod2 <- as.xts(pred_mod2, order.by = date(X_test2_post))

plot(as.xts(y_test2_post, order.by = date(X_test2_post)), type = "l")
lines(pred_mod2, type="l", col = "red")

mape(y_test2_post, pred_mod2)
rmse(y_test2_post, pred_mod2)
```

# MODELLO 3 - RITARDI + WDAY + YDAY + PIOGGIA + COLORE COVID + FESTIVITA' (UNA DUMMY PER OGNI SINGOLA FESTA)

```{r}
dum_festivi_ts <- xts(fest_post[, 2:18], as.Date(as.character(fest_post$date), format = "%Y-%m-%d"))
# Tengo solo le dummy fino alla data contenuta nei dati
dum_festivi_ts <- window(dum_festivi_ts, start = "2020-05-07", end = "2022-04-28")
```

```{r}
r1_post3 <- subset(r1_post2, select = -c(2))
r1_post3 <- cbind(r1_post3, dum_festivi_ts)
```

```{r}
X3 <- embed(r1_post3$lordototale, 15)

y3 <- X3[, 1]

X3 <- cbind(X3[, -1], r1_post3[-(1:14), c("Pioggia","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno","ColoreCOVID_rosso",
                                          "yday","wday","dec8","dec24","dec25","dec26","dec31","jan1","jan6","apr25","mag1","jun2","aug15",
                                          "oct31","nov1","eastsun","eastermon","martgrasso","bridge")])

# Split training-test

y_train3_post <- y3[train_ndx]
X_train3_post <- X3[train_ndx, ]

y_test3_post <- y3[test_ndx]
X_test3_post <- X3[test_ndx,]

# Addestramento modello

mod3_rit_dummy <- randomForest(X_train3_post, y_train3_post,
                    xtest = X_test3_post,
                    ytest = y_test3_post)

pred_mod3 <- mod3_rit_dummy$test$predicted
pred_mod3 <- as.xts(pred_mod3, order.by = date(X_test3_post))

plot(as.xts(y_test3_post, order.by = date(X_test3_post)), type = "l")
lines(pred_mod3, type="l", col = "red")

mape(y_test3_post, pred_mod3)
rmse(y_test3_post, pred_mod3)
```

# Cross-validation

```{r}
source("My-TSCrossValidation-Functions.R")
```

```{r}
#f_mod1 <- function(Y, h, newxreg = NULL) {
#  # Definizione e train del modello
#  rf1 <- randomForest(y~., data = Y)
#  
#  # Definizione vettore vuoto che conterrà le previsioni
#  y_hat <- numeric(h)
#  
#  ## Regressori per le previsioni
#  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
#  X <- Y[nrow(Y), -15, drop = FALSE] 
#  colnames(X) <- colnames(Y)[-1] 
#  
#  # Itero la generazione dei regressori sulle h previsioni
#  for (i in 1:h) {
#    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella #foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
#    # Produco lo shift in X
#    # X viene aggionrato ogni volta, le stime entrano dei regressori
#    X[1, 2:14] <- X[1, 1:13]
#    X[1, 1] <- y_hat[i]
#  }
#  return(y_hat)
#}
#
#f_mod2 <- function(Y, h, newxreg = NULL) {
#  # Definizione e train del modello
#  rf1 <- randomForest(y~., data = Y)
#  
#  # Definizione vettore vuoto che conterrà le previsioni
#  y_hat <- numeric(h)
#  
#  ## Regressori per le previsioni
#  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
#  X <- Y[nrow(Y), -15, drop = FALSE] 
#  colnames(X) <- colnames(Y)[-1] 
#  
#  # Itero la generazione dei regressori sulle h previsioni
#  for (i in 1:h) {
#    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella #foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
#    # Produco lo shift in X
#    # X viene aggionrato ogni volta, le stime entrano dei regressori
#    X[1, 2:14] <- X[1, 1:13]
#    # Aggiorniamo anche i regressori
#    X[1, c("Festivo","Pioggia","yday","wday","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno",
#                                          "ColoreCOVID_rosso")] <- newxreg[i, #c("Festivo","Pioggia","yday","wday","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno",
#                                          "ColoreCOVID_rosso")]
#    X[1, 1] <- y_hat[i]
#  }
#  return(y_hat)
#}
#
#f_mod3 <- function(Y, h, newxreg = NULL) {
#  # Definizione e train del modello
#  rf1 <- randomForest(y~., data = Y)
#  
#  # Definizione vettore vuoto che conterrà le previsioni
#  y_hat <- numeric(h)
#  
#  ## Regressori per le previsioni
#  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
#  X <- Y[nrow(Y), -15, drop = FALSE] 
#  colnames(X) <- colnames(Y)[-1] 
#  
#  # Itero la generazione dei regressori sulle h previsioni
#  for (i in 1:h) {
#    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella #foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
#    # Produco lo shift in X
#    # X viene aggionrato ogni volta, le STIME entrano dei regressori
#    X[1, 2:14] <- X[1, 1:13]
#    # Aggiorniamo anche i regressori con i VALORI VERI del validation
#    X[1, 15:ncol(X)] <- newxreg[i, ]
#    X[1, 1] <- y_hat[i]
#  }
#  return(y_hat)
#}
```

Fixed func

```{r}
f_mod1 <- function(Y, h, newxreg = NULL) {
  # Definizione e train del modello
  rf1 <- randomForest(y~., data = Y)
  
  # Definizione vettore vuoto che conterrà le previsioni
  y_hat <- numeric(h)
  
  ## Regressori per le previsioni
  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
  X <- Y[nrow(Y), -15, drop = FALSE] 
  colnames(X) <- colnames(Y)[-1] 
  
  # Itero la generazione dei regressori sulle h previsioni
  for (i in 1:h) {
    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
    # Produco lo shift in X
    # X viene aggionrato ogni volta, le stime entrano dei regressori
    X[1, 2:14] <- X[1, 1:13]
    X[1, 1] <- y_hat[i]
  }
  return(y_hat)
}

f_mod2 <- function(Y, h, newxreg = NULL) {
  # Definizione e train del modello
  rf1 <- randomForest(y~., data = Y)
  
  # Definizione vettore vuoto che conterrà le previsioni
  y_hat <- numeric(h)
  
  ## Regressori per le previsioni
  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
  X <- Y[nrow(Y), -15, drop = FALSE] 
  colnames(X) <- colnames(Y)[-1] 
  
  # Itero la generazione dei regressori sulle h previsioni
  for (i in 1:h) {
    # Aggiorniamo anche i regressori
    X[1, c("Festivo","Pioggia","yday","wday","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno",
                                          "ColoreCOVID_rosso")] <- newxreg[i, c("Festivo","Pioggia","yday","wday","ColoreCOVID_arancione","ColoreCOVID_giallo","ColoreCOVID_nessuno",
                                          "ColoreCOVID_rosso")]
    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
    # Produco lo shift in X
    # X viene aggionrato ogni volta, le stime entrano dei regressori
    X[1, 2:14] <- X[1, 1:13]
    X[1, 1] <- y_hat[i]
  }
  return(y_hat)
}

f_mod3 <- function(Y, h, newxreg = NULL) {
  # Definizione e train del modello
  rf1 <- randomForest(y~., data = Y)
  
  # Definizione vettore vuoto che conterrà le previsioni
  y_hat <- numeric(h)
  
  ## Regressori per le previsioni
  # Prendo ultima riga della matrice dei regressori, elimino l'ultimo ritardo
  X <- Y[nrow(Y), -15, drop = FALSE] 
  colnames(X) <- colnames(Y)[-1] 
  
  # Itero la generazione dei regressori sulle h previsioni
  for (i in 1:h) {
    # Aggiorniamo anche i regressori con i VALORI VERI del validation
    X[1, 15:ncol(X)] <- newxreg[i, ]
    y_hat[i] <- predict(rf1, X, predict.all = TRUE)$individual |> median() # predict.all=True mantiene la stima data da tutti gli alberi nella foresta. Dopodichè si vanno a selezionare tutti e a prenderne la mediana (in alternativa, la media)
    # Produco lo shift in X
    # X viene aggionrato ogni volta, le STIME entrano dei regressori
    X[1, 2:14] <- X[1, 1:13]
    X[1, 1] <- y_hat[i]
  }
  return(y_hat)
}
```


```{r}
# Parametri di cross-validation globali
h = 60 # 6 settimane
initial = 365 # Un anno
window = NULL # no moving window, si rolling origin

# Calcolo tempo di computazione
start.time <- Sys.time()
print(start.time)

# Pre processing modello 1

rf_r1 <- xts(postcovid1[, "lordototale"], as.Date(as.character(postcovid1$data), format = "%Y-%m-%d"))

# CV su MODELLO 1

e_1 <- tsCV_RandomForest(my_xts = rf_r1[,1], forecastfunction = f_mod1, h=h, initial = initial, window = window)
e1 <- e_1$e
e1_percentage <- e_1$e_percentage
e1_groundtruth <- e_1$y_groundtruth
e1_estimate <- e_1$y_estimate

# Pre processing modello 2

r1_post2 <- xts(postcovid1[, c("lordototale", "Festivo", "Pioggia", "ColoreCOVID")], as.Date(as.character(postcovid1$data), format = "%Y-%m-%d"))

r1_post2$Festivo[r1_post2$Festivo=="False"] <- 0
r1_post2$Festivo[r1_post2$Festivo=="True"] <- 1

r1_post2$Pioggia[r1_post2$Pioggia==""] <- 0
r1_post2$Pioggia[r1_post2$Pioggia=="True"] <- 1

r1_post2$ColoreCOVID[r1_post2$ColoreCOVID == ""] <- "nessuno"
r1_post2 <- fastDummies::dummy_cols(r1_post2, select_columns = "ColoreCOVID", remove_most_frequent_dummy = TRUE, remove_selected_columns = TRUE)
r1_post2 <- as.xts(r1_post2[-1], as.Date(r1_post2$index))
yday <- yday(time(r1_post2))
wday <- wday(time(r1_post2), week_start = getOption("lubridate.week.start", 1))
r1_post2 <- cbind(r1_post2, yday, wday)

# CV su MODELLO 2

e_2 <- tsCV_RandomForest(my_xts = r1_post2[,1], xreg = r1_post2[,-1], forecastfunction = f_mod2, h=h, initial = initial, window = window)
e2 <- e_2$e
e2_percentage <- e_2$e_percentage
e2_groundtruth <- e_2$y_groundtruth
e2_estimate <- e_2$y_estimate

# Pre processing modello 3

dum_festivi_ts <- xts(fest_post[, 2:18], as.Date(as.character(fest_post$date), format = "%Y-%m-%d"))
dum_festivi_ts <- window(dum_festivi_ts, start = "2020-05-07", end = "2022-04-28")
r1_post3 <- subset(r1_post2, select = -c(2))
r1_post3 <- cbind(r1_post3, dum_festivi_ts)

# CV su MODELLO 3

e_3 <- tsCV_RandomForest(my_xts = r1_post3[,1], xreg = r1_post3[,-1], forecastfunction = f_mod3, h=h, initial = initial, window = window)
e3 <- e_3$e
e3_percentage <- e_3$e_percentage
e3_groundtruth <- e_3$y_groundtruth
e3_estimate <- e_3$y_estimate

end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)
```

Salvataggio

```{r}
matrices <- list(e1 = e1, e1_percentage = e1_percentage, e1_estimate = e1_estimate, e1_groundtruth = e1_groundtruth, e3 = e3, e3_percentage = e3_percentage, e3_estimate = e3_estimate, e3_groundtruth = e3_groundtruth, e2 = e2, e2_percentage = e2_percentage, e2_estimate = e2_estimate, e2_groundtruth = e2_groundtruth)

for (i in 1:length(matrices)) {
  write.csv(data.frame(date=index(matrices[[i]]), coredata(matrices[[i]])),
            paste0("./Errors/RandomForest/RandomForest_Covid_", names(matrices)[i], ".csv"))
}

```

```{r}
RMSE_mod1 <- sqrt(colMeans(e1^2, na.rm = TRUE))
RMSE_mod2 <- sqrt(colMeans(e2^2, na.rm = TRUE))
RMSE_mod3 <- sqrt(colMeans(e3^2, na.rm = TRUE))

# Zoom in
#plot(1:42, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2500,5000))
#lines(1:42, RMSE_mod2, type="l",col=2)
#lines(1:42, RMSE_mod3, type="l",col=3)
#legend("topleft",legend=c("1_RandomForest_noregr","2_RandomForest_regr","3_RandomForest_regr"),col=1:3,lty=1)

# Zoom out
plot(1:60, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2000,5000))
lines(1:60, RMSE_mod2, type="l",col=2)
lines(1:60, RMSE_mod3, type="l",col=3)
legend("topleft",legend=c("1_RandomForest_noregr","2_RandomForest_regr","3_RandomForest_regr_DUmmy"),col=1:3,lty=1)
```

```{r}
MAE_mod1 <- colMeans(abs(e1), na.rm = TRUE)
MAE_mod2 <- colMeans(abs(e2), na.rm = TRUE)
MAE_mod3 <- colMeans(abs(e3), na.rm = TRUE)

plot(1:60, MAE_mod1, type="l", col=1, xlab="horizon", ylab="MAE", ylim = c(0,13000))
lines(1:60, MAE_mod2, type="l",col=2)
lines(1:60, MAE_mod3, type="l",col=3)
legend("topleft",legend=c("1_RandomForest_noregr","2_RandomForest_regr","3_RandomForest_regrDummy"),col=1:3,lty=1)
```

```{r}
MAPE_mod1 <- colMeans(abs(e1_percentage), na.rm = TRUE)
MAPE_mod2 <- colMeans(abs(e2_percentage), na.rm = TRUE)
MAPE_mod3 <- colMeans(abs(e3_percentage), na.rm = TRUE)

plot(1:60, MAPE_mod1, type="l", col=1, xlab="horizon", ylab="MAPE", ylim = c(0,20))
lines(1:60, MAPE_mod2, type="l",col=2)
lines(1:60, MAPE_mod3, type="l",col=3)
legend("topleft",legend=c("1_RandomForest_noregr","2_RandomForest_regr","3_RandomForest_regrDummy"),col=1:3,lty=1)
```

