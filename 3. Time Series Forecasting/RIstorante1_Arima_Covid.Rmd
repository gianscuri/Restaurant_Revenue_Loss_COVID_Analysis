---
title: "ARIMA - Ristorante1"
output:
  prettydoc::html_pretty:
    df_print: paged
    highlight: vignette
    theme: architect
    toc: yes
    toc_depth: 5
  beamer_presentation:
    colortheme: lily
    fig_caption: no
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    theme: Hannover
    toc: yes
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '5'
  pdf_document:
    toc: yes
    toc_depth: 5
  slidy_presentation:
    highlight: default
  ioslides_presentation:
    css:
    - css/fonts.css
    - css/custom.css
    - css/title-slide.css
    - css/slide-background.css
    includes:
      before_body: html/TimeSeriesAnalysis.html
    toc: yes
    transition: default
    widescreen: yes
course: Progetto Data Science Lab
---

```{r}
# Clean Workspace
# rm(list=ls())
```

```{r setup, include=FALSE}
# Use 'verbatim = TRUE' as chunk option to show chunk code as is
require(knitr)
hook_source_def = knit_hooks$get('source')
knit_hooks$set(source = function(x, options){
  if (!is.null(options$verbatim) && options$verbatim){
    opts = gsub(",\\s*verbatim\\s*=\\s*TRUE\\s*", "", options$params.src)
    bef = sprintf('\n\n    ```{r %s}\n', opts, "\n")
    stringr::str_c(bef, paste(knitr:::indent_block(x, "    "), collapse = '\n'), "\n    ```\n")
  } else {
     hook_source_def(x, options)
  }
})
```

# Setting & Function

```{r include=FALSE}
set.seed(100)

# Setting librerie utili
# Package names
packages <- c("readxl",  "readr", "forecast", "dplyr", "ggplot2",
              "lubridate", "KFAS", "tseries", "xts", "fastDummies", "TSstudio") 

# Install packages if not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))


# MAPE 
mape <- function(actual,pred){
  mape <- mean(abs((actual - pred)/actual))*100
  return (mape)
}

#MAE
mae <- function(actual,pred){
  mae <- mean(abs((actual - pred)))
  return (mae)
}

#MSE
rmse <- function(actual, pred){
  rmse <- sqrt(mean((actual - pred)^2))
  return (rmse)
}

# Significatività dei parametri
pars_test <- function(coef, var_coef){
  test <- (1-pnorm(abs(coef)/sqrt(diag(var_coef))))*2
  return(test)
}

# Grafico errore percentuale 
err_plot <- function(actual, pred){
  require(xts)
  err_perc <- ((actual - xts(pred, order.by = index(actual)))/(xts(actual, order.by = index(actual))))*100
  return(plot(err_perc, ylab="% errore", main="Errore percentuale di previsione"))

}

```

## Load Data & Manipulation

Periodo considerato: dal **07/05/2020** (giorno di riapertura post 1° lockdown)

```{r}
df <- read.csv("..\\Dati ristoranti\\post-covid_r1.csv")
head(df)
```

Considero solo le variabili d'interesse

```{r}
df$data  <- parse_date(df$data, "%Y-%m-%d", locale = locale("it"))
df <- subset(df,
             select = c("data", "lordototale", "Season", "Giorno","Weekend", "Festivo", "Pioggia", "ColoreCOVID", "Dose1", "Dose2", "DoseUnica", "Booster1", "Booster3Dosi", "Booster2", "BENZINA.LITRO", "GASOLIO_AUTO.LITRO", "GPL.LITRO","GASOLIO_RISCALDAMENTO.LITRO"))

```

```{r}
# Creo dataframe contenente le sole variabili esplicative
xreg<- df[,-2]
```

```{r}
# Sistemo le varie variabili
xreg$Pioggia[xreg$Pioggia ==""] <- "False" 
xreg$ColoreCOVID[xreg$ColoreCOVID==""] <- "NoColore"
xreg$Dose1[is.na(xreg$Dose1)] <- 0
xreg$Dose2[is.na(xreg$Dose2)] <- 0
xreg$DoseUnica[is.na(xreg$DoseUnica)] <- 0
xreg$Booster1[is.na(xreg$Booster1)] <- 0
xreg$Booster2[is.na(xreg$Booster2)] <- 0
xreg$Booster3Dosi[is.na(xreg$Booster3Dosi)] <- 0
```

```{r}
# Controllo che non ci siano na
xreg[is.na(xreg)==TRUE,] # Non ci sono Nan
```

```{r}
vendite_r1 <- df[,2]
vendite_r1[is.na(vendite_r1)] # Non ci sono NaN
 
```

```{r}
# Valori pari a zero
vendite_r1[vendite_r1 == 0] 
# 9 valori a zero, probabilmente chiusure oppure mancanza di registrazioni degli incassi (inverosimile che il risotante abbia effettivamente incassato zero, ASSUNZIONE!!)
df$data[df$lordototale == 0 ] # Acuni giorni sono festività, altri invece no. 
```

Nella serie storica pre-covid tali dati sono stati regsitrati, il che equivale al fatto che il ristorante era aperto. Per non distorcere troppo le previsioni, e considerando che i valori mancanti sono comunque pochi, viene deciso di imputare tali valori mancanti

```{r}
#La libreria inputTS gestisce ovviamente i NaN e non i valori uguali a zero
vendite_r1[vendite_r1 == 0] <- NaN
```

```{r}
# Trasformo in ts
vendite_r1 <- msts(vendite_r1, seasonal.periods=c(7,365.25), ts.frequency = 7)
autoplot(vendite_r1, ylab = "Vendite")
```

## Imputazione dei valori mancanti

```{r}
library(imputeTS)
ggplot_na_distribution(vendite_r1)
statsNA(vendite_r1)
```

```{r}
# Imputazione tramite algoritmo di Kalman
vendite_r1_nona <- na_kalman(vendite_r1)
ggplot_na_imputations(vendite_r1, vendite_r1_nona)
```
```{r}
trend <-xts(vendite_r1_dec[,2], order.by = df$data, frequency = 7)
write.zoo(trend, file="C:\\Users\\marco\\OneDrive\\UNIMIB_DataScience\\99-PROJECTS\\DataScienceLab2022\\Analisi predittive\\trend.csv", sep=",")
```

```{r}
vendite_r1 <- na_kalman(vendite_r1)
```

```{r}
vendite_r1_dec <- mstl(vendite_r1) 
autoplot(vendite_r1_dec)
```

Si nota come l'andamento della serie storica sia molto irregolare. Questo è dovuto al fatto che i dati sono influenzati dall'andamento della pandemia. In paeticolare si notano dei trend crescenti e decrescenti successivi, causati dall'introduzione del colore delle regioni, che a seconda dell'andamento dei contagi imponenvano delle restrizioni sulle attività commerciali.

```{r}
plot(vendite_r1, main="Trend Vendite giornaliere", xlab ="Time", ylab="Fatturato")
lines(vendite_r1_dec[,2], col="blue", lwd=2)
```

## Stazionarietà della serie storica

La serie storica è ovviamente non stazionaria, per i seguenti motivi:

-   Presenza di stagionalità (non stazionarietà stagionale)
-   Presenza di un trend (osservazioni sistematicamente sopra o sotto la media)
-   Possibile non stazionarietà in varianza (se guardiamo il grafico della decomposizione, la parte stagionale risulta avere un andamento in varianza non constante)

```{r}
ndiffs(vendite_r1)
nsdiffs(vendite_r1)
```

```{r}
nsdiffs(diff(vendite_r1))
```

```{r}
kpss.test(vendite_r1)
```

```{r}
vendite_r1_diff7 <- diff(vendite_r1,7)
autoplot(vendite_r1_diff7)
tsdisplay(vendite_r1_diff7)
```

```{r}
ndiffs(vendite_r1_diff7)
```

I vari test effettuati ci indichiano una chiara non stazionarietà della serie storica. In particolare notiamo come si probabilmente necessaria sia una differenziazione non stagionale che una stagionale.

Proviamo a vedere se una trasformazione dei dati per stabilizzare la varianza possa portare a non dover applicare due differenziazioni

```{r}
BoxCox.lambda(vendite_r1)
```

Abbiamo un valore negativo non molto lontano da zero, il che ci può far pensare che una trasformazione logaritmica possa migliorare la situazione

```{r}
plot(log(vendite_r1))
```

```{r}
autoplot(mstl(log(vendite_r1)))
```

```{r}
ndiffs(log(vendite_r1))
nsdiffs(log(vendite_r1))
```

Permane ancora una non stazionarietà sia stagionale che non stagionale. Andremo successivamente a valutare quali differenziazioni considerare.

## Variabili stagionali

```{r}
dum_day_df <- df[, c("data", "Giorno")]
dum_day_df[,"Giorno"] <- as.factor(dum_day_df$Giorno)
dum_day_df <- dummy_cols(dum_day_df, select_columns = c("Giorno"), 
                      # remove_first_dummy = TRUE, 
                      remove_selected_columns = TRUE)
dum_day_df <- subset(dum_day_df, select = -c(data,Giorno_Monday)) #Tolgo il Lunedì come variabile dummy
dum_day_df

# La funzione Arima vuole in input una matrice per i regressori
dum_day <- as.matrix(dum_day_df)
```

```{r}
#dummy annuali
dum_ann_df <- read_xlsx("..\\Dati aggiuntivi\\fest_postcovid.xlsx", col_types = NULL)
dum_ann_df <- subset(dum_ann_df, date < "2022-05-01", select = -date) # Non considero le osservazioni dopo il  30/04/22 (fine della serie storica)

dum_ann_df <- as.data.frame(lapply(dum_ann_df, as.integer)) # Trasformo tutte le colonne in interi e ri-trasformo in dataframe
head(dum_ann_df)

# La funzione Arima vuole in input una matrice per i regressori
dum_ann <- as.matrix(dum_ann_df)
```

```{r}
# Unisco tutto in un unico dataframe tutti le dummy stagionali e altri vari regressori

xreg <- cbind(dum_ann_df, dum_day_df, subset(xreg, select = -c(data, Giorno, Weekend, Festivo)))

# Rinonimo alcune colonne
colnames(xreg)[36] = "Riscaldamento" 
colnames(xreg)[35] = "Gpl"
colnames(xreg)[34] = "Gasolio"
colnames(xreg)[33] = "Benzina"
colnames(xreg)[25] = "Pioggia_True"
colnames(xreg)[36] = "Riscaldamento"

# Variabile dummy Pioggia
xreg$Pioggia_True[xreg$Pioggia_True == "True"] <- 1 # Trasformo in dummy
xreg$Pioggia_True[xreg$Pioggia_True == "False"] <- 0
xreg$Pioggia_True <- as.integer(xreg$Pioggia_True) # Trasformo in integer

#Creo variabili Dummy per il colore della regione
# Per il periodo pre-Colori imposto colore a bianco
xreg$ColoreCOVID[xreg$ColoreCOVID == "NoColore"] <- "bianco"


xreg[,"ColoreCOVID"] <- as.factor(xreg$ColoreCOVID)
xreg <- dummy_cols(xreg, select_columns = c("ColoreCOVID"), 
                      remove_most_frequent_dummy = TRUE, #tolgo dummy zona bianca
                      remove_selected_columns = TRUE) #inplace
head(xreg)
```

```{r}
# Termini di Fourier per modellare stagionalità

four <- fourier(vendite_r1, K=c(3,15))
four <- as.matrix((four))

```

## Costruzione dataset per le previsioni

```{r}
# Fourier
four_predict <- fourier(vendite_r1, K=c(3,15), h=60)
four_predict <- as.matrix(four_predict)

# Dummy annuali
dum_ann_df_predict <- read_xlsx("..\\Dati aggiuntivi\\fest_postcovid.xlsx", col_types = NULL)
dum_ann_df_predict <- subset(dum_ann_df_predict, date > "2022-04-30" & date < "2022-07-01" , select = -date)

# Dummy settimanali
dum_day_predict <-  read_xlsx("..\\Dati aggiuntivi\\dum_day_predict.xlsx", col_types = NULL)

dum_day_predict[,"Giorno"] <- as.factor(dum_day_predict$Giorno)
dum_day_predict <- dummy_cols(dum_day_predict, select_columns = c("Giorno"),
                      remove_selected_columns = TRUE)
dum_day_predict <- subset(dum_day_predict, select = -c(Data,Giorno_Lunedì))
head(dum_day_predict)
```

# Stima modelli

## Partizionamento dei datasets

```{r}
# Divsione training-test serie storica
split_vendite <- ts_split(vendite_r1, sample.out =60)
train <- split_vendite$train
test <- split_vendite$test

# Controllo le dimensioni di training e test
length(train)
length(test)
```

```{r}
# Divisione training-test matrice dummy giornaliere

train_date <- nrow(dum_day)-60
train_dumday<- dum_day[1:train_date,]
test_dumday <- dum_day[-c(1:train_date),]

# Controllo le dimensioni di training e test
length(train_dumday[,1])
length(test_dumday[,1])
```

```{r}
# Divisione training-test dummy annuali

train_date <- nrow(dum_ann)-60
train_dumann<- dum_ann[1:train_date,]
test_dumann <- dum_ann[-c(1:train_date),]

# Controllo le dimensioni di training e test
length(train_dumann[,1])
length(test_dumann[,1])
```

```{r}
# Divisione training-test termini di Fourier

train_date <- nrow(four)-60
train_four<- four[1:train_date,]
test_four <- four[-c(1:train_date),]

# Controllo le dimensioni di training e test
length(train_four[,1])
length(test_four[,1])
```

```{r}
# Divsione training-test dataframe xreg

train_date <- nrow(xreg)-60
train_xreg<- xreg[1:train_date,]
test_xreg <- xreg[-c(1:train_date),]

# Controllo le dimensioni di training e test
length(train_xreg[,1])
length(test_xreg[,1])

```


```{r}
tsdisplay(vendite_r1)
```

```{r}
tsdisplay(diff(vendite_r1,7))
```

```{r}
tsdisplay(log(vendite_r1))
```

## Modello 1

-   Differenza stagionale di ordine 1

-   Componente AR stagionale di ordine 1 :

-   Componente MA stagionale di ordine 1 :

-   Differenza non stagionale di ordine 1

-   Componente MA non stagionale di ordine 1

-   Componente AR non stagionale di ordine 2

-   Costante non inclusa

```{r}
mod1 <- Arima(y = train,
              order = c(2, 1, 1),
              list(order = c(1, 1, 1)),
              include.constant = FALSE,
              lambda = "auto"
              )
```

### Diagnostica:

```{r}
summary(mod1)
```

```{r}
tsdisplay(mod1$residuals) 
```

```{r}
checkresiduals(mod1, test = FALSE)
```

```{r}
checkresiduals(mod1, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod1$coef, mod1$var.coef)
```

```{r}
mod1_auto <- auto.arima(train, lambda = "auto", stepwise = FALSE, approximation = FALSE) # Minimizza AIC
```

```{r}
summary(mod1_auto)
```

```{r}
tsdisplay(mod1_auto$residuals) 
```

```{r}
checkresiduals(mod1_auto, test = FALSE)
```

```{r}
checkresiduals(mod1_auto, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod1_auto$coef, mod1_auto$var.coef)
```

```{r}
# Fit prime 10 settimane mod1
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod1$fitted[1:70], col="red", lwd=3)
```

```{r}
# Fit prime 10 settimane mod1_auto
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod1_auto$fitted[1:70], col="red", lwd=3)
```

Il *mod1_auto* presenta delle caratteristiche leggermente migliori rispetto a *mod1*.

### Previsioni

```{r}
pred_mod1 <- forecast(mod1_auto, h = length(test), 
                      level = 95)
```

```{r}
autoplot(pred_mod1)
```

```{r}
plot(test, 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod1$lower), max(pred_mod1$upper)), main = "Predictions")
lines(pred_mod1$mean, col="red", lwd=3)

```

```{r}
mape(test, pred_mod1$mean)
```

```{r}
mae(test, pred_mod1$mean)
```

```{r}
rmse(test, pred_mod1$mean)
```

```{r}
# err_plot(test, pred_mod1$mean)
```

## Modello2

Includiamo le dummy giornaliere

```{r}
mod2 <- Arima(y = train,
              order = c(1, 1, 3),
              list(order = c(1, 0, 0)),
              include.constant = FALSE,
              xreg = train_dumday,
              lambda = "auto"
              )
```

```{r}
summary(mod2)
```

```{r}
tsdisplay(mod2$residuals) 
```

```{r}
checkresiduals(mod2, test = FALSE)
```

```{r}
checkresiduals(mod2, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod2$coef, mod2$var.coef)
```

```{r}
mod2_auto <- auto.arima(train, xreg = train_dumday, lambda = "auto", stepwise = FALSE, approximation = FALSE)
```

```{r}
summary(mod2_auto) # Stesso modello di quello identificato sopra, consideriamo mod2
```

```{r}
# Fit prime 10 settimane
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod2$fitted[1:70], col="red", lwd=3)
```

### Previsioni

```{r}
pred_mod2 <- forecast(mod2, h = nrow(test_dumday), 
                      level = 95,
                      xreg = test_dumday)
```

```{r}
autoplot(pred_mod2)
```

```{r}
plot(test, 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod2$lower), max(pred_mod2$upper)), main = "Predictions")
lines(pred_mod2$mean, col="red", lwd=3)
```

```{r}
mape(test, pred_mod2$mean)
```

```{r}
mae(test, pred_mod2$mean)
```

```{r}
rmse(test, pred_mod2$mean)
```

```{r}
# err_plot(test, pred_mod1$mean)
```

## Modello 3

Come regressori vengono usati i termini di fourier: 3 armoniche per la stagionalità settimanale e 15 per quella annuale
```{r}
mod3 <- Arima(y = train,
              order = c(1, 1, 2),
              list(order = c(1, 0, 1)),
              include.constant = TRUE,
              xreg = train_four,
              lambda = "auto"
              )
```

```{r}
summary(mod3)
```

```{r}
tsdisplay(mod3$residuals) 
```

```{r}
checkresiduals(mod3, test = FALSE)
```

```{r}
checkresiduals(mod3, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod3$coef, mod3$var.coef)
```

```{r}
# mod3_auto <- auto.arima(train, xreg = train_four, lambda = "auto", stepwise = FALSE)
```

```{r}
summary(mod3_auto)
```

```{r}
tsdisplay(mod3_auto$residuals) 
```

```{r}
checkresiduals(mod3_auto, test = FALSE)
```

```{r}
checkresiduals(mod3_auto, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod3_auto$coef, mod3_auto$var.coef)
```


Scelgo il modello *mod3* in quanto presenta caratteristiche migliori per quanto riguarda errori di previsioni e residui, anche se risulta essere meno parsimonioso

```{r}
pred_mod3 <- forecast(mod3, h = nrow(test_four), 
                      level = 95,
                      xreg = test_four
                      )
```

```{r}
autoplot(pred_mod3)
```

```{r}
plot(test, 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod3$lower), max(pred_mod3$upper)), main = "Predictions")
lines(pred_mod3$mean, col="red", lwd=3)
```

```{r}
mape(test, pred_mod3$mean)
```

```{r}
mae(test, pred_mod3$mean)
```

```{r}
rmse(test, pred_mod3$mean)
```

```{r}
# err_plot(test, pred_mod1$mean)
```

## Modello 4

Regressori considerati:

-   Termini di fourier per modellare la stagionalità

-   Variabili relative al COVID (zone)

-   Altre variabili (i.e. Costo riscaldamento, Pioggia)

```{r}
# Costruzione della matrice dei regressori per il modello 4

xreg_mod4_train <- cbind(train_four, subset(train_xreg, select = c("Pioggia_True", "Benzina", "Gasolio", "ColoreCOVID_arancione", "ColoreCOVID_giallo", "ColoreCOVID_rosso")))
xreg_mod4_train <- as.matrix(xreg_mod4_train)
xreg_mod4_test <- cbind(test_four, subset(test_xreg, select = c("Pioggia_True", "Benzina", "Gasolio", "ColoreCOVID_arancione", "ColoreCOVID_giallo", "ColoreCOVID_rosso")))
xreg_mod4_test <- as.matrix(xreg_mod4_test)
```


```{r}
mod4 <- Arima(y = train,
              order = c(2, 1, 3),
              list(order = c(1, 0, 0)),
              include.constant = FALSE,
              xreg = xreg_mod4_train,
              lambda = "auto"
              )
```

```{r}
summary(mod4)
```

```{r}
tsdisplay(mod4$residuals) 
```

```{r}
checkresiduals(mod4, test = FALSE)
```

```{r}
checkresiduals(mod4, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod4$coef, mod4$var.coef)
```
```{r}
# Fit prime 10 settimane
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod4$fitted[1:70], col="red", lwd=3)
```
```{r}
mod4_auto <- auto.arima(train, xreg = xreg_mod4_train, lambda = "auto")
```

```{r}
summary(mod4_auto)
```

```{r}
tsdisplay(mod4_auto$residuals) 
```

```{r}
checkresiduals(mod4_auto, test = FALSE)
```

```{r}
checkresiduals(mod4_auto, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod4_auto$coef, mod4_auto$var.coef)
```
```{r}
# Fit prime 10 settimane
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod4_auto$fitted[1:70], col="red", lwd=3)
```

 Viene scelto il *mod4_auto* in quanto più parsimonioso

```{r}
pred_mod4 <- forecast(mod4_auto, h = nrow(xreg_mod4_test), 
                      level = 95,
                      xreg = xreg_mod4_test
                      )
```

```{r}
autoplot(pred_mod4)
```

```{r}
plot(test, 
     col = "blue", lwd=0.5, 
     # ylim = c(min(pred_mod4$lower), max(pred_mod4$upper)), 
     main = "Predictions")
lines(pred_mod4$mean, col="red", lwd=3)
```

```{r}
mape(test, pred_mod4$mean)
```

```{r}
mae(test, pred_mod4$mean)
```

```{r}
rmse(test, pred_mod4$mean)
```
## Modello5

Regressori considerati:

-   Dummy Annuali

-   Dummy Giornaliere

-   Variabili relative al COVID (zone)

-   Altre variabili (i.e. Costo riscaldamento, Pioggia)

```{r}
# Costruzione della matrice dei regressori per il modello 4

# Train
xreg_mod5_train <- cbind(train_dumday, train_dumann, subset(train_xreg, select = c("Pioggia_True", "Benzina", "Gasolio", "ColoreCOVID_arancione", "ColoreCOVID_giallo", "ColoreCOVID_rosso")))
xreg_mod5_train <- as.matrix(xreg_mod5_train)

xreg_mod5_test <- cbind(test_dumday, test_dumann,  subset(test_xreg, select = c("Pioggia_True", "Benzina", "Gasolio", "ColoreCOVID_arancione", "ColoreCOVID_giallo", "ColoreCOVID_rosso")))
xreg_mod5_test <- as.matrix(xreg_mod5_test)
```

```{r}
mod5_auto <- auto.arima(train, xreg = xreg_mod5_train, lambda = "auto")
```

```{r}
summary(mod5_auto)
```

```{r}
tsdisplay(mod5_auto$residuals) 
```

```{r}
checkresiduals(mod5_auto, test = FALSE)
```

```{r}
checkresiduals(mod5_auto, test = "LB", lag = 25, plot = FALSE)
```

```{r}
pars_test(mod5_auto$coef, mod5_auto$var.coef)
```
```{r}
# Fit prime 10 settimane
plot(train[1:70], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values", type = "l")
lines(mod5_auto$fitted[1:70], col="red", lwd=3)
```

```{r}
pred_mod5 <- forecast(mod5_auto, h = nrow(xreg_mod5_test), 
                      level = 95,
                      xreg = xreg_mod5_test
                      )
```

```{r}
autoplot(pred_mod5)
```

```{r}
plot(test, 
     col = "blue", lwd=0.5, 
     # ylim = c(min(pred_mod4$lower), max(pred_mod4$upper)), 
     main = "Predictions")
lines(pred_mod5$mean, col="red", lwd=3)
```

```{r}
mape(test, pred_mod5$mean)
```

```{r}
mae(test, pred_mod5$mean)
```

```{r}
rmse(test, pred_mod5$mean)
```
```{r}
train_eval <- data.frame(Modelllo=c("Modello1", "Modello2", "Modello3", "Modello4", "Modello5"),
                         RMSE = c(rmse(train, mod1_auto$fitted), 
                                rmse(train, mod2$fitted), 
                                rmse(train, mod3$fitted),
                                rmse(train, mod4_auto$fitted),
                                rmse(train, mod5_auto$fitted)),
                         MAE = c(mae(train, mod1_auto$fitted),
                                mae(train, mod2$fitted),
                                mae(train, mod3$fitted),
                                mae(train, mod4_auto$fitted),
                                 mae(train, mod5_auto$fitted)),
                         MAPE = c(mape(train, mod1_auto$fitted),
                                  mape(train, mod2$fitted),
                                  mape(train, mod3$fitted),
                                  mape(train, mod4_auto$fitted),
                                  mape(train, mod5_auto$fitted)),
                         AIC = c(mod1_auto$aic, mod2$aic, mod3$aic, mod4_auto$aic, mod5_auto$aic))
```


```{r}
test_eval <- data.frame(Modelllo=c("Modello1", "Modello2", "Modello3", "Modello4", "Modello5"),
                         RMSE = c(rmse(test, pred_mod1$mean), 
                                rmse(test, pred_mod2$mean), 
                                rmse(test, pred_mod3$mean),
                                rmse(test, pred_mod4$mean),
                                rmse(test, pred_mod5$mean)),
                         MAE = c(mae(test, pred_mod1$mean),
                                mae(test, pred_mod2$mean),
                                mae(test, pred_mod3$mean),
                                mae(test, pred_mod4$mean),
                                mae(test, pred_mod5$mean)),
                         MAPE = c(mape(test, pred_mod1$mean),
                                  mape(test, pred_mod2$mean),
                                  mape(test, pred_mod3$mean),
                                  mape(test, pred_mod4$mean),
                                  mape(test, pred_mod5$mean)))

```

```{r}
train_eval
test_eval
```
# Evaluation: Confronto forecasting performance dei modelli

## Scelta misura di *forecasting accuracy*

Al fine di confrontare i diversi modelli definiti precedentemente è importante valutare le performance in termini forecasting accuracy. Prima di definire la procedura di calcolo della forecasting accuracy è importante selezionare la propria misura di accuratezza.

Si sceglie di utilizzare due misure di accuratezza (**MAE, RMSE e MSE**) di tipo **scale-dependent** perchè:

-   Misure di accuratezza basate su percentage errors e scaled errors (unit-free) sono indicate per comparare le performance di forecasting tra data set diversi

-   Errori di tipo scale-dependent sono nella stessa scala dei dati, ma in questo caso non è un problema

-   Si evitano tutte le problematiche relative alle misure di percentage errors legate:

    -   al fatto che l'errore viene diviso per il valore dell'osservazione (valori infiniti per y che tende a 0)

    -   penalità maggiori per errori negativi piuttosto che quelli positivi

## Procedura di *Cross-Validation* con *rolling forecasting origin*

Effettuo la procedura di *Time-Series Cross Validation* o *Evaluating on a Rolling Forecasting Origin* al fine di:

-   Confrontare i diversi modelli in termini di Performance di Forecasting

-   Potera allenare i modelli sull'intero dataset e non perdere i dati del test set (essendo questo già piccolo)

-   Ottenere comunque due misure di performarmance di accuratezza di forecasting accuracy

-   Determino la forecasting accuracy (come MAE/RMSE/MSE) per k-step avanti dove k (chiamato h, orizzonte, nella funzione `tsCV()`) sarà il mio orizzonte di previsione nel periodo covid

    -   Confrontare l'andamento dei diversi modelli all'aumentare degli step ci consentirà di selezionare

-   Parametri di cross-validation -\> Scelgo come tipologia di Time Series Cross Validation quella **Constant Holdout**

    -   Scelgo arbitrariamente una finestra iniziale (**fixed origin**) di training (il numero minimo di osservazioni necessario a stimare il modello) come 60 -\> parametro `initial`

    -   **Non-Constant Holdout** -\> in modo da utilizzare tutti i dati per il training (altrimenti il training si fermerebbe all'osservazione n-h)

    -   **Non-Constant In-Sample -\>** Non impostiamo il parametro `window`, che altrimenti andrebbe a settare un dimensione fissata del training set e quindi una moving window


## Definizione funzione di Time Series Cross-Validation (`tsCV_ARIMA()`)

_**Prima si eseguire questa parte del notebook eseguire le celle sopra.**_


```{r}
source("My-TSCrossValidation-Functions.R")
```

```{r}
summary(mod4_auto)
```


## Definizione funzioni dei modelli

Non includo in modello 5 in quanto presenta elevato overfitting e pessime performance sul test set.

```{r}

# Calcolo tempo di computazione
start.time <- Sys.time()
print(start.time)

# Definisco la forecast-function per i diversi modelli

#1_ARIMA
f_mod1 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(1, 0, 1),
                 seasonal = list(order = c(1, 1, 1)),
                 include.constant = FALSE,
                 lambda = "auto"),
           h = h)
}

#2_ARIMA w/dum_day
f_mod2 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(1, 1, 3),
                 seasonal = list(order = c(1, 0, 0)),
                 xreg = xreg,
                 include.constant = FALSE,
                 lambda = "auto"),
           h = h,
           xreg=newxreg)
}

#3_ARIMA w/Fourier
f_mod3 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(1, 1, 2),
                 seasonal = list(order = c(1, 0, 1)),
                 xreg = xreg,
                 include.constant = TRUE,
                 lambda = "auto"),
           h = h,
           xreg=newxreg)
}
#4_SARIMAX w/Fourier & xreg
f_mod4 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(2, 0, 0),
                 seasonal = list(order = c(2, 0, 1)),
                 xreg = xreg,
                 include.constant = TRUE,
                 lambda = "auto"),
           h = h,
           xreg=newxreg)
}

```
```{r}
# Parametri di cross-validation globali per i primi due modelli
h = 60 # 2 mesi
initial = 180 # 3 volte l'orizzonte
window = NULL

start.time <- Sys.time()
print(start.time)

# Stima degli errori di previsione con CV

e_1 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod1, h=h, initial = initial, window = window)
#e1 <- tail(e1, n = -initial)
e1 <- e_1$e
e1_percentage <- e_1$e_percentage
e1_estimate <- e_1$y_estimate
e1_groundtruth <- e_1$y_groundtruth


xreg2 <- dum_day
e_2 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod2, h=h, xreg=xreg2, initial = initial)
#e2 <- tail(e1, n = -initial)
e2 <- e_2$e
e2_percentage <- e_2$e_percentage
e2_estimate <- e_2$y_estimate
e2_groundtruth <- e_2$y_groundtruth


end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)

```

```{r}
# Parametri di cross-validation globali per il terzo e quarto modello

h = 60 # 2 mesi
initial = 540 #180*3 modelli maggiormente complessi richiedono un training set iniziale più ampio
window = NULL

start.time <- Sys.time()
print(start.time)


xreg3 <- four
e_3 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod3, h=h, xreg=xreg3, initial = initial)
#e3 <- tail(e3, n = -initial)
e3 <- e_3$e
e3_percentage <- e_3$e_percentage
e3_estimate <- e_3$y_estimate
e3_groundtruth <- e_3$y_groundtruth


xreg4 <- rbind(xreg_mod4_train, xreg_mod4_test)
e_4 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod4, h=h, xreg=xreg4, initial = initial)
#e4 <- tail(e4, n = -initial)
e4 <- e_4$e
e4_percentage <- e_4$e_percentage
e4_estimate <- e_4$y_estimate
e4_groundtruth <- e_4$y_groundtruth

end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)
```

## Salvataggio errori

```{r}
matrices <- list(e1 = e1, e1_percentage = e1_percentage, e1_estimate = e1_estimate, e1_groundtruth = e1_groundtruth, e3 = e3, e3_percentage = e3_percentage, e3_estimate = e3_estimate, e3_groundtruth = e3_groundtruth, e2 = e2, e2_percentage = e2_percentage, e2_estimate = e2_estimate, e2_groundtruth = e2_groundtruth)

for (i in 1:length(matrices)) {
  # Aggiungo la colonna date
  df_temp <- xts(matrices[[i]], as.Date(as.character(df$data), format = "%Y-%m-%d"))
  write.csv(data.frame(date=index(df_temp), coredata(df_temp)),
            paste0("./Errors/ARIMA/ARIMA_Covid_", names(matrices)[i], ".csv"))
}

```

```{r}
# cAMBIO PARAMETRI GLOBALI PER IL TERZO E QUARTO MODELLO

h = 60 # 2 mesi
initial = 365 #180*3 modelli maggiormente complessi richiedono un training set iniziale più ampio
window = NULL

start.time <- Sys.time()
print(start.time)


xreg3 <- four
e_3_1 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod3, h=h, xreg=xreg3, initial = initial)
#e3 <- tail(e3, n = -initial)
e3_1 <- e_3_1$e
e3_percentage_1 <- e_3_1$e_percentage
e3_estimate_1 <- e_3_1$y_estimate
e3_groundtruth_1 <- e_3_1$y_groundtruth


xreg4 <- rbind(xreg_mod4_train, xreg_mod4_test)
e_4_1 <- tsCV_ARIMA(y = vendite_r1, forecastfunction = f_mod4, h=h, xreg=xreg4, initial = initial)
#e4 <- tail(e4, n = -initial)
e4_1 <- e_4_1$e
e4_percentage_1 <- e_4_1$e_percentage
e4_estimate_1 <- e_4_1$y_estimate
e4_groundtruth_1 <- e_4_1$y_groundtruth

end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)
```


## Confrontro tra i modelli

### RMSE

```{r}
RMSE_mod1 <- sqrt(colMeans(e1^2, na.rm = TRUE))
RMSE_mod2 <- sqrt(colMeans(e2^2, na.rm = TRUE))
RMSE_mod3 <- sqrt(colMeans(e3^2, na.rm = TRUE))
RMSE_mod4 <- sqrt(colMeans(e4^2, na.rm = TRUE))
#RMSE_mod6 <- sqrt(colMeans(e6^2, na.rm = TRUE))


# Zoom in
plot(1:60, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2500,6500))
lines(1:60, RMSE_mod2, type="l",col=2)
lines(1:60, RMSE_mod3, type="l",col=3)
lines(1:60, RMSE_mod4, type="l",col=4)
legend("bottomright",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_ARIMA4"),col=1:4,lty=1)

```

### RMdSE

```{r}
library(robustbase)
RdMSE_mod1 <- sqrt(colMedians(e1^2, na.rm = TRUE, hasNA = TRUE))
RdMSE_mod2 <- sqrt(colMedians(e2^2, na.rm = TRUE, hasNA = TRUE))
RdMSE_mod3 <- sqrt(colMedians(e3^2, na.rm = TRUE, hasNA = TRUE))
RdMSE_mod4 <- sqrt(colMedians(e4^2, na.rm = TRUE, hasNA = TRUE))
#RMSE_mod6 <- sqrt(colMeans(e6^2, na.rm = TRUE))


# Zoom in
plot(1:60, RdMSE_mod1, type="l", col=1, xlab="horizon", ylab="RdMSE", ylim = c(1000,4500))
lines(1:60, RdMSE_mod2, type="l",col=2)
lines(1:60, RdMSE_mod3, type="l",col=3)
lines(1:60, RdMSE_mod4, type="l",col=4)
legend("bottomright",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_ARIMA4"),col=1:4,lty=1)

```

**RMSE Medi**

```{r}
mean(RMSE_mod1)
mean(RMSE_mod2)
mean(RMSE_mod3)
mean(RMSE_mod4)
```

### MAE

```{r}
MAE_mod1 <- colMeans(abs(e1), na.rm = TRUE)
MAE_mod2 <- colMeans(abs(e2), na.rm = TRUE)
MAE_mod3 <- colMeans(abs(e3), na.rm = TRUE)
MAE_mod4 <- colMeans(abs(e4), na.rm = TRUE)

plot(1:60, MAE_mod1, type="l", col=1, xlab="horizon", ylab="MAE", ylim = c(0,6000))
lines(1:60, MAE_mod2, type="l",col=2)
lines(1:60, MAE_mod3, type="l",col=3)
lines(1:60, MAE_mod4, type="l",col=4)

legend("bottomright",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_ARIMA4"),col=1:4,lty=1)
```

### MAPE

```{r}
MAPE_mod1 <- colMeans(abs(e1_percentage), na.rm = TRUE)
MAPE_mod2 <- colMeans(abs(e2_percentage), na.rm = TRUE)
MAPE_mod3 <- colMeans(abs(e3_percentage), na.rm = TRUE)
MAPE_mod4 <- colMeans(abs(e4_percentage), na.rm = TRUE)


plot(1:42, MAPE_mod1, type="l", col=1, xlab="horizon", ylab="MAPE", ylim = c(0,30))
lines(1:42, MAPE_mod2, type="l",col=2)
lines(1:42, MAPE_mod3, type="l",col=3)
lines(1:42, MAPE_mod4, type="l",col=4)

legend("topleft",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_ARIMA4"),col=1:4,lty=1)
```


```{r}
RMSE_mod1 <- sqrt(colMeans(e1^2, na.rm = TRUE))
RMSE_mod2<- sqrt(colMeans(e2^2, na.rm = TRUE))
RMSE_mod3_1 <- sqrt(colMeans(e3_1^2, na.rm = TRUE))
RMSE_mod4_1 <- sqrt(colMeans(e4_1^2, na.rm = TRUE))
#RMSE_mod6 <- sqrt(colMeans(e6^2, na.rm = TRUE))


# Zoom in
plot(1:60, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2500,10000))
lines(1:60, RMSE_mod2, type="l",col=2)
lines(1:60, RMSE_mod3_1, type="l",col=3)
lines(1:60, RMSE_mod4_1, type="l",col=4)
legend("topleft",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_ARIMA4"),col=1:4,lty=1)
```

