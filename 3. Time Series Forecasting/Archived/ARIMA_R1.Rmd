---
title: "ARIMA - Ristorante1"
output:
  prettydoc::html_pretty:
    df_print: paged
    highlight: vignette
    theme: architect
    toc: yes
    toc_depth: 5
  beamer_presentation:
    colortheme: lily
    fig_caption: no
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    theme: Hannover
    toc: yes
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '5'
  pdf_document:
    toc: yes
    toc_depth: 5
  slidy_presentation:
    highlight: default
  ioslides_presentation:
    css:
    - css/fonts.css
    - css/custom.css
    - css/title-slide.css
    - css/slide-background.css
    includes:
      before_body: html/TimeSeriesAnalysis.html
    toc: yes
    transition: default
    widescreen: yes
course: Progetto Data Science Lab
---

```{r}

```

```{r}

```

```{r}

```

```{r}
# Clean Workspace
rm(list=ls())
```

```{r setup, include=FALSE}
# Use 'verbatim = TRUE' as chunk option to show chunk code as is
require(knitr)
hook_source_def = knit_hooks$get('source')
knit_hooks$set(source = function(x, options){
  if (!is.null(options$verbatim) && options$verbatim){
    opts = gsub(",\\s*verbatim\\s*=\\s*TRUE\\s*", "", options$params.src)
    bef = sprintf('\n\n    ```{r %s}\n', opts, "\n")
    stringr::str_c(bef, paste(knitr:::indent_block(x, "    "), collapse = '\n'), "\n    ```\n")
  } else {
     hook_source_def(x, options)
  }
})
```

# Setting & Function

```{r}
set.seed(100)

# Setting librerie utili
# Package names
packages <- c("readxl",  "readr", "forecast", "dplyr", "ggplot2",
              "lubridate", "KFAS", "tseries", "xts", "fastDummies") 

# Install packages if not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))


# Setting working directory
# working_dir = "C:/Users/marco/OneDrive/UNIMIB_DataScience/99-PROJECTS/DataScienceLab2022/Dati ristoranti"
# setwd(working_dir)

# MAPE 
mape <- function(actual,pred){
  mape <- mean(abs((actual - pred)/actual))*100
  return (mape)
}

#MSE
rmse <- function(actual, pred){
  rmse <- sqrt(mean((actual - pred)^2))
  return (rmse)
}

# Significatività dei parametri
pars_test <- function(coef, var_coef){
  test <- (1-pnorm(abs(coef)/sqrt(diag(var_coef))))*2
  return(test)
}

# Grafico errore percentuale 
err_plot <- function(actual, pred){
  require(xts)
  err_perc <- ((actual - xts(pred, order.by = index(actual)))/(xts(actual, order.by = index(actual))))*100
  return(plot(err_perc, ylab="% errore", main="Errore percentuale di previsione"))

}
```

# Load data

```{r}
# file: Dati ristoranti\pre-covid_r1.csv
r1 <- read.csv("..\\Dati ristoranti\\pre-covid_r1.csv")
r1$data  <- parse_date(r1$data, "%Y-%m-%d", locale = locale("it"))
head(r1)
```

# Data preparation

```{r}
# ts vendite
vendite_r1 <- r1[, c(7,9)]
head(vendite_r1)
```

```{r}
str(vendite_r1)
```

```{r}
# Trasformo ts in oggetto xts
vendite_r1 <- as.xts(vendite_r1[,-1], order.by = vendite_r1[,1])
head(vendite_r1)
```

```{r}
plot(vendite_r1)
```

## Stagionalità

Confrontiamo la media degli incassi dei giorni feriali (non festivi) rispetto alla media del weekend (considero weekend Venerdì-Sabato-Domenica)

```{r}
# Media dei giorni feriali

feriali <- r1[r1$Weekend == 'False',c("data", "lordototale", "Giorno", "Festivo")]
feriali <- feriali[feriali$Festivo == "False",]
tapply(feriali$lordototale, feriali$Giorno, mean)
```

```{r}
# Media dei giorni "weekend"
weekend <- r1[r1$Weekend == 'True',c("data", "lordototale", "Giorno", "Festivo")]
# weekend <- weekend[weekend$Festivo == "False",]
tapply(weekend$lordototale, weekend$Giorno, mean)
```

```{r}
# Confronto media giorni lun-gio in base a se è festivo o meno
festivo_noweekend <- r1[r1$Weekend == 'False',c("data", "lordototale", "Giorno", "Festivo")]
tapply(festivo_noweekend$lordototale, festivo_noweekend$Festivo, mean)
```

```{r}
# Costruzione dummy per modellare stagionalità a 7 giorni

require('fastDummies')
dum_day <- r1[, c("data", "Giorno")]
dum_day[,"Giorno"] <- as.factor(dum_day$Giorno)
dum_day <- dummy_cols(dum_day, select_columns = c("Giorno"), 
                      remove_first_dummy = TRUE, 
                      remove_selected_columns = TRUE)
dum_day
```

```{r}
# Costruzione dummuy per weekend e festivi
dum_week <- r1[, c("data", "Festivo")]
dum_week[, "Festivo"] <- as.factor(dum_week$Festivo)
dum_week <- dummy_cols(dum_week, select_columns = "Festivo", 
                       remove_first_dummy = TRUE, 
                       remove_selected_columns = TRUE)
dum_week
```

```{r}
# xts object con tutte le variabili dummy
dum <- cbind(dum_day, dum_week)
dum <- xts(dum[, -1], dum$data)
dum <- subset(dum, select = -c(data))
#rm(list=c("dum_day", "dum_week"))
head(dum)
```

```{r}
df <- cbind(vendite_r1, dum)
head(df)
```

## Partizionamento del dataset

```{r}
# Divisione training-test set
train_date <- nrow(df) *0.8
train_temp <- df[1:train_date,]
test <- df[-c(1:train_date),] # Usare alla fine
```

```{r}
# Training - validation set 
train_date_rid <- nrow(train_temp)*0.9
train <- train_temp[1:train_date_rid,]
validation <- train_temp[-c(1:train_date_rid),]
rm(list="train_temp")
```

# Stazionarietà della serie storica

```{r}
# Intera serie storica
autoplot(train[,1])
```

La serie storica sembra non avere una tendenza di medio/lungo periodo a crescere o scendere (trend). Valutiamo l'andamento della funzione di autocorrelazione (totale e parziale)

```{r}
tsdisplay(train[,1])
```

ACF risulta avere ritardi significativi che decadono a zero molto lentamente, sintomo di una non stazionarietà della serie storica. Notiamo come i ritardi maggiormente significativi sono quelli ai ritardi stagionali multipli di 7.

## Ljung-Box test

(a non-stationary signal will have a low p-value)

```{r}
lag.length = 25
Box.test(train[,1], lag=lag.length, type="Ljung-Box")

```

Il test di Ljung-Box conferma l'ipotesi di non stazionarietà.

La non stazionarietà potrebbe però essere dovuta alla presenza di stagionalità nella serie storica:

```{r}
# Augmented Dickey–Fuller (ADF) t-statistic test for unit root
options(warn=-1)
require(tseries)

adf.test(train[,1])
```

Come effettivamente viene suggerito dal test di Dickey Fuller (valuta la presenza di radici unitarie)

# Differenza stagionale

```{r}
diff7 <- diff(train[,1], 7)
tsdisplay(diff7)
```

```{r}
lag.length = 25
Box.test(diff7, lag=lag.length, type="Ljung-Box")
rm(list="diff7")
```

Il test indica che è ancora presente correlazione seriale. Notiamo però come la ACF, nei primi 25 ritardi, abbia solamente il settimo ritardo significativi, mentre ora la PACF tende a zero molto più lentamente rispetto a prima (con ritardi particolarmente significativi ai ritardi stagionali multipli di 7)

# Identificazione del modello

## Modello1

-   Componente AR stagionale: ACF presenta correlazione significativa al ritardo 7
-   Componente MA stagionale: PACF presenta correlazioni particolarmente significative ai riatdi multipli di 7
-   Componente MA non stagionale di ordine 2
-   Dummy come regressori esterni
-   Costante non inclusa

```{r}
mod1 <- Arima(y = train$vendite_r1,
              order = c(0, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = train[, -1],
              include.constant = FALSE,
              )
```

### Diagnostica:

```{r}
summary(mod1)
```

```{r}
tsdisplay(mod1$residuals) 
```

```{r}
pars_test(mod1$coef, mod1$var.coef)
```

```{r}
checkresiduals(mod1)
```

```{r}
lag.length = 25
Box.test(mod1$residuals, lag=lag.length, type="Ljung-Box")
```

```{r}
plot(train[1:28,1], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values")
lines(xts(mod1$fitted[1:28], order.by = index(train[1:28])), col="red", lwd=2.5)
```

### Previsioni

```{r}
# Al momento vengono fatte previsioni 44 passi in avanti (lunghezza del validation set)
pred_mod1 <- forecast(mod1, h = 44, 
                      level = 95,
                      xreg = validation[, -1])
```

```{r}
autoplot(pred_mod1)
```

```{r}
plot(validation[,1], 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod1$lower), max(pred_mod1$upper)), main = "Predictions")
lines(xts(pred_mod1$mean, order.by = index(validation)), col="red", lwd=3)

```

```{r}
mape(validation[,1], xts(pred_mod1$mean, order.by = index(validation)))
```

```{r}
rmse(validation[,1], xts(pred_mod1$mean, order.by = index(validation)))
```

```{r}
err_plot(validation[,1], xts(pred_mod1$mean, order.by = index(validation)))
```

## Modello2

-   Componente AR stagionale: ACF presenta correlazione significativa al ritardo 7
-   Componente MA stagionale: PACF presenta correlazioni particolarmente significative ai riatdi multipli di 7
-   Componente MA non stagionale di ordine 2
-   Componente AR non stagionle di ordine 5
-   Dummy come regressori esterni
-   Costante non inclusa

```{r}
mod2 <- Arima(y = train$vendite_r1,
              order = c(5, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = train[, -1],
              include.constant = FALSE,
              )
```

### Diagnostica

```{r}
summary(mod2)
```

```{r}
tsdisplay(mod2$residuals) 
```

```{r}
pars_test(mod2$coef, mod2$var.coef)
```

```{r}
lag.length = 25
Box.test(mod2$residuals, lag=lag.length, type="Ljung-Box")
```

```{r}
checkresiduals(mod2)
```

```{r}
plot(train[1:28,1], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values")
lines(xts(mod2$fitted[1:28], order.by = index(train[1:28])), col="red", lwd=2.5)
```

### Previsioni

```{r}
# Al momento vengono fatte previsioni 44 passi in avanti (lunghezza del validation set)
pred_mod2 <- forecast(mod2, h = 44, 
                      level = 95,
                      xreg = validation[, -1])
```

```{r}
autoplot(pred_mod2)
```

```{r}
plot(validation[,1], 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod2$lower), max(pred_mod2$upper)), main = "Fitted Value")
lines(xts(pred_mod2$mean, order.by = index(validation)), col="red", lwd=3)

```

```{r}
mape(validation[,1], xts(pred_mod2$mean, order.by = index(validation)))
```

```{r}
rmse(validation[,1], xts(pred_mod2$mean, order.by = index(validation)))
```

```{r}
err_plot(validation[,1], xts(pred_mod2$mean, order.by = index(validation)))
```

## Modello3

-   Componente AR stagionale: ACF presenta correlazione significativa al ritardo 7
-   Componente MA stagionale: PACF presenta correlazioni particolarmente significative ai riatdi multipli di 7
-   Componente MA non stagionale di ordine 2
-   Componente AR non stagionale di ordine 3
-   Dummy come regressori esterni
-   Costante non inclusa

```{r}
mod3 <- Arima(y = train$vendite_r1,
              order = c(3, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = train[, -1],
              include.constant = FALSE,
              )
```

### Diagnostica

```{r}
summary(mod3)
```

```{r}
tsdisplay(mod3$residuals) 
```

```{r}
pars_test(mod3$coef, mod3$var.coef)
```

```{r}
lag.length = 25
Box.test(mod3$residuals, lag=lag.length, type="Ljung-Box")
```

```{r}
checkresiduals(mod3)
```

```{r}
plot(train[,1], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values")
lines(xts(mod3$fitted, order.by = index(train)), col="red", lwd=2.5)
```

### Previsioni

```{r}
# Al momento vengono fatte previsioni 44 passi in avanti (lunghezza del validation set)
pred_mod3 <- forecast(mod3, h = 44, 
                      level = 95,
                      xreg = validation[, -1])
```

```{r}
autoplot(pred_mod3)
```

```{r}
plot(validation[,1], 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod3$lower), max(pred_mod3$upper)), main = "Fitted Value")
lines(xts(pred_mod3$mean, order.by = index(validation)), col="red", lwd=3)

```

```{r}
mape(validation[,1], xts(pred_mod3$mean, order.by = index(validation)))
```

```{r}
rmse(validation[,1], xts(pred_mod3$mean, order.by = index(validation)))
```

```{r}
err_plot(validation[,1], xts(pred_mod3$mean, order.by = index(validation)))
```

## Modello 4 SARIMAX

-   Componente AR stagionale: ACF presenta correlazione significativa al ritardo 7
-   Componente MA stagionale: PACF presenta correlazioni particolarmente significative ai riatdi multipli di 7
-   Componente MA non stagionale di ordine 2
-   Componente AR non stagionale di ordine 3
-   Dummy come regressori esterni
-   Vari regressori (dei regressori disponibili sono stati incluse, dopo varie prove, solamente quelli significativi)
-   Costante non inclusa

```{r}
# xts object regressori

# Imposto a zero i giorni dove m.m. Pioggia  == 0 (Prima NaN)
r1$Precipitazioni.mm.[is.na(r1$Precipitazioni.mm.)] <- 0

# in data 23/11/2018 valore Precipitazione anomalo (-999.01) impostato a zero
r1$Precipitazioni.mm.[r1$data == "2018-11-23"] <- 0

# Manca modalità "False" per la variabile pioggia, aggiungo
r1$Pioggia[r1$Pioggia==''] <- "False"

df_reg <- df
df_reg$Benzina <- r1$BENZINA.LITRO
df_reg$Benzina <- r1$GASOLIO_AUTO.LITRO
df_reg$Gpl <- r1$GPL.LITRO
df_reg$Riscaldamento <- r1$GASOLIO_RISCALDAMENTO.LITRO
```

```{r}
# Costruzione delle dummy, dove necessario
require(fastDummies)
dum_pioggia <- r1[, c("data", "Pioggia")]
dum_pioggia[,"Pioggia"] <- as.factor(dum_pioggia$Pioggia)
dum_pioggia <- dummy_cols(dum_pioggia, select_columns = c("Pioggia"), 
                      remove_first_dummy = TRUE, 
                      remove_selected_columns = TRUE)
dum_pioggia
```

```{r}
df_reg$Pioggia_True <- dum_pioggia$Pioggia_True
```

Rifaccio la divisione trainin/validation/test set con il df_reg appena creato

```{r}
# Divisione training-test set
train_date <- nrow(df_reg) *0.8
train_temp <- df_reg[1:train_date,]
test_reg <- df_reg[-c(1:train_date),] # Usare alla fine
```

```{r}
# Training - validation set 
train_date_rid <- nrow(train_temp)*0.9
train_reg <- train_temp[1:train_date_rid,]
validation_reg <- train_temp[-c(1:train_date_rid),]
```

```{r}
mod4 <- Arima(y = train_reg$vendite_r1,
              order = c(3, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = train_reg[, -c(1,11,12,14)], # Rimosse le variabili non significative
              include.constant = FALSE,
              )
```

### Diagnostica

```{r}
summary(mod4)
```

```{r}
tsdisplay(mod4$residuals) 
```

```{r}
pars_test(mod4$coef, mod4$var.coef)
```

```{r}
lag.length = 25
Box.test(mod4$residuals, lag=lag.length, type="Ljung-Box")
```

```{r}
checkresiduals(mod4)
```

```{r}
plot(train[1:28,1], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values")
lines(xts(mod4$fitted[1:28], order.by = index(train[1:28])), col="red", lwd=2.5)
```

### Previsioni

```{r}
# Al momento vengono fatte previsioni 44 passi in avanti (lunghezza del validation set)
pred_mod4 <- forecast(mod4, h = 44, 
                      level = 95,
                      xreg = validation_reg[, -c(1,11,12,14)])
```

```{r}
autoplot(pred_mod4)
```

```{r}
plot(validation_reg[,1], 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod4$lower, min(validation_reg[,1])), max(pred_mod4$upper, max(validation_reg[,1]))), main = "Fitted Value")
lines(xts(pred_mod4$mean, order.by = index(validation_reg)), col="red", lwd=3)

```

```{r}
mape(validation_reg[,1], xts(pred_mod4$mean, order.by = index(validation_reg)))
```

```{r}
rmse(validation_reg[,1], xts(pred_mod4$mean, order.by = index(validation_reg)))
```

```{r}
err_plot(validation_reg[,1], pred_mod4$mean)
```

## Modello 6: Forecasting with Prophet

```{r}
library(prophet)
# Prophet vuole in input un df contenente data e dati storici
df_prophet <- r1[, c(7,9)]
head(df_prophet)
```

```{r}
colnames(df_prophet)[1] <- "ds"
colnames(df_prophet)[2] <- "y"
```

```{r}
# Divisione training-test set
train_date <- nrow(df_prophet) *0.8
train_temp <- df_prophet[1:train_date,]
test <- df_prophet[-c(1:train_date),] # Usare alla fine
```

```{r}
# Training - validation set 
train_date_rid <- nrow(train_temp)*0.9
train <- train_temp[1:train_date_rid,]
validation <- train_temp[-c(1:train_date_rid),]
```

```{r}
mod_prop <- prophet(train, weekly.seasonality = TRUE)
```

```{r}
future <- make_future_dataframe(mod_prop, periods = 44)
```

```{r}
forecast <- predict(mod_prop, future)
```

```{r}
plot(mod_prop, forecast)
```

```{r}
prophet_plot_components(mod_prop, forecast)
```

```{r}
dyplot.prophet(mod_prop, forecast)
```

## Modello 5: SARIMAX CON NUOVI REGRESSORI

```{r}
# Dataset festività 
# fest <- read_xlsx("C:\\Users\\marco\\OneDrive\\UNIMIB_DataScience\\99-PROJECTS\\DataScienceLab2022\\Dati aggiuntivi\\fest.xlsx", 
#                  col_types = NULL)
fest <- read_xlsx("..\\Dati aggiuntivi\\fest.xlsx", 
                  col_types = NULL)
str(fest)
```

```{r}
index <- 2:ncol(fest)
fest[,index] <- lapply(fest[,index], as.integer)
```

```{r}
# xts object con variabili dummy giorno e festività 
dum_day_fest <-cbind(dum_day, fest)
dum_day_fest <- subset(dum_day_fest, select = -c(date))
dum_day_fest <- xts(dum_day_fest[, -1], dum_day_fest$data)
```

```{r}
df_fest <- cbind(vendite_r1, dum_day_fest)
```

```{r}
# Divisione training-test set
train_date <- nrow(df_fest) *0.8
train_temp <- df_fest[1:train_date,]
test <- df_fest[-c(1:train_date),] # Usare alla fine
```

```{r}
# Training - validation set 
train_date_rid <- nrow(train_temp)*0.9
train <- train_temp[1:train_date_rid,]
validation <- train_temp[-c(1:train_date_rid),]
rm(list="train_temp")
```

```{r}
mod5 <- Arima(y = train$vendite_r1,
              order = c(3, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = train[, -1], # Rimosse le variabili non significative
              include.constant = FALSE,
              )
```

```{r}
summary(mod5)
```

```{r}
tsdisplay(mod5$residuals) 
```

```{r}
pars_test(mod5$coef, mod5$var.coef)
```

```{r}
lag.length = 25
Box.test(mod5$residuals, lag=lag.length, type="Ljung-Box")
```

```{r}
checkresiduals(mod5)
```

```{r}
plot(train[1:28,1], 
     col = "blue", lwd=0.5, 
     main = "Fitted Values")
lines(xts(mod5$fitted[1:28], order.by = index(train[1:28])), col="red", lwd=2.5)
```

### Previsioni

```{r}
# Al momento vengono fatte previsioni 44 passi in avanti (lunghezza del validation set)
pred_mod5 <- forecast(mod5, h = 44, 
                      level = 95,
                      xreg = validation[, -1])
```

```{r}
autoplot(pred_mod5)
```

```{r}
plot(validation[,1], 
     col = "blue", lwd=0.5, 
     ylim = c(min(pred_mod5$lower, min(validation[,1])), max(pred_mod5$upper, max(validation[,1]))), main = "Fitted Value")
lines(xts(pred_mod5$mean, order.by = index(validation)), col="red", lwd=3)

```

```{r}
mape(validation[,1], xts(pred_mod5$mean, order.by = index(validation)))
```

```{r}
rmse(validation[,1], xts(pred_mod5$mean, order.by = index(validation)))
```

```{r}
err_plot(validation[,1], pred_mod5$mean)
```

# Evaluation: Confronto ***forecasting performance*** **dei modelli**

## Scelta misura di *forecasting accuracy*

Al fine di confrontare i diversi modelli definiti precedentemente è importante valutare le performance in termini forecasting accuracy. Prima di definire la procedura di calcolo della forecasting accuracy è importante selezionare la propria misura di accuratezza.

Si sceglie di utilizzare due misure di accuratezza (**MAE, RMSE e MSE**) di tipo **scale-dependent** perchè:

-   Misure di accuratezza basate su percentage errors e scaled errors (unit-free) sono indicate per comparare le performance di forecasting tra data set diversi

-   Errori di tipo scale-dependent sono nella stessa scala dei dati, ma in questo caso non è un problema

-   Si evitano tutte le problematiche relative alle misure di percentage errors legate:

    -   al fatto che l'errore viene diviso per il valore dell'osservazione (valori infiniti per y che tende a 0)

    -   penalità maggiori per errori negativi piuttosto che quelli positivi

## Procedura di *Cross-Validation* con *rolling forecasting origin*

Effettuo la procedura di *Time-Series Cross Validation* o *Evaluating on a Rolling Forecasting Origin* al fine di:

-   Confrontare i diversi modelli in termini di Performance di Forecasting

-   Potera allenare i modelli sull'intero dataset e non perdere i dati del test set (essendo questo già piccolo)

-   Ottenere comunque due misure di performarmance di accuratezza di forecasting accuracy

-   Determino la forecasting accuracy (come MAE/RMSE/MSE) per k-step avanti dove k (chiamato h, orizzonte, nella funzione `tsCV()`) sarà il mio orizzonte di previsione nel periodo covid

    -   Confrontare l'andamento dei diversi modelli all'aumentare degli step ci consentirà di selezionare

-   Parametri di cross-validation -\> Scelgo come tipologia di Time Series Cross Validation quella **Constant Holdout**

    -   Scelgo arbitrariamente una finestra iniziale (**fixed origin**) di training (il numero minimo di osservazioni necessario a stimare il modello) come 60 -\> parametro `initial`

    -   **Non-Constant Holdout** -\> in modo da utilizzare tutti i dati per il training (altrimenti il training si fermerebbe all'osservazione n-h)

    -   **Non-Constant In-Sample -\>** Non impostiamo il parametro `window`, che altrimenti andrebbe a settare un dimensione fissata del training set e quindi una moving window

### Test su Mod1

```{r}
start.time <- Sys.time()
print(start.time)
# Definisco la forecast-function

f_mod1 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(0, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}


xreg <- df[, -1]

initial = 90 
e <- tsCV(y = df$vendite_r1, forecastfunction = f_mod1, h=90, xreg=xreg, initial = initial)
e <- tail(e, n = -initial)

end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)

#print(e)
#sqrt(mean(e^2, na.rm=TRUE))
```

```{r}
print(nrow(df))
print(nrow(e)+ initial)

# Posso osservare dal print della coda della matrice degli errori come siano presenti NA, questo conferma che tsCV() effettua CV con Non-Constant Holdout
#print(tail(e))
```

```{r}
#print(head(e, 5))
print("MSE:")
MSE_mod1 <- colMeans(e^2, na.rm = TRUE)
print(MSE_mod1)
print("RMSE:")
RMSE_mod1 <- sqrt(colMeans(e^2, na.rm = TRUE))
print(RMSE_mod1)
print("MAE:")
MAE_mod1 <- colMeans(abs(e), na.rm = TRUE)
print(MAE_mod1)

data.frame(h = 1:90, MSE = RMSE_mod1) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()
```

Ora stimo il modello nella sua interezza e confronto RMSE ottenuto dai residui con quello ottenuto con CV:

```{r}
mod1 <- Arima(y = df$vendite_r1,
              order = c(0, 0, 2),
              list(order = c(1, 0, 1), period = 7),
              xreg = df[, -1],
              include.constant = FALSE,
              )
summary(mod1)
```

-   Come atteso l'RMSE in previsione è sempre maggiore di quello ottenuto sui residui di trainin (medi primo allenamento del modello)

### Confronto tra i modelli

**Cross-Validation**

```{r}

# Calcolo tempo di computazione
start.time <- Sys.time()
print(start.time)

# Definisco la forecast-function per i diversi modelli

#1_ARIMA
f_mod1 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(0, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}

#2_ARIMA
f_mod2 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(5, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}

#3_ARIMA
f_mod3 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(3, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}

#4_SARIMAX
f_mod4 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(3, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}

#5_SARIMAX
f_mod5 <- function(x, h, xreg, newxreg) { 
  forecast(Arima(x,
                 order = c(3, 0, 2),
                 seasonal = list(order = c(1, 0, 1), period = 7),
                 xreg = xreg,
                 include.constant = FALSE
                 ),
           h = h,
           xreg=newxreg)
}

#6_Prophet
f_mod6 <- function(x, h, xreg, newxreg) { 
  forecast(prophet(x,
                 weekly.seasonality = TRUE
                 ))
}


# Parametri di cross-validation globali
h = 90
initial = 60

# Stima degli errori di previsione con CV

xreg1 <- df[, -1]
e1 <- tsCV(y = df$vendite_r1, forecastfunction = f_mod1, h=h, xreg=xreg1, initial = initial)
e1 <- tail(e1, n = -initial)

xreg2 <- df[, -1]
e2 <- tsCV(y = df$vendite_r1, forecastfunction = f_mod2, h=h, xreg=xreg2, initial = initial)
e2 <- tail(e2, n = -initial)

xreg3 <- df[, -1]
e3 <- tsCV(y = df$vendite_r1, forecastfunction = f_mod3, h=h, xreg=xreg3, initial = initial)
e3 <- tail(e3, n = -initial)

# Runna il preprocessing nella sezione del modello 4 (df_reg) !
xreg4 <- df_reg[, -c(1,11,12,14)]
e4 <- tsCV(y = df_reg$vendite_r1, forecastfunction = f_mod4, h=h, xreg=xreg4, initial = initial)
e4 <- tail(e4, n = -initial)

# Runna il preprocessing nella sezione del modello 5 (SARIMAX) !
xreg5 <- df_fest[, -1]
e5 <- tsCV(y = df_fest$vendite_r1, forecastfunction = f_mod5, h=h, xreg=xreg5, initial = initial)
e5 <- tail(e5, n = -initial)

# Runna il preprocessing nella sezione del modello 6 (df_prophet) !
# e6 <- tsCV(y = df_prophet, forecastfunction = f_mod6, h=h, initial = initial)
# e6 <- tail(e6, n = -initial)


end.time <- Sys.time()
print(end.time)
time.taken <- end.time - start.time
print(time.taken)
```

**Accuratezze**

```{r}
RMSE_mod1 <- sqrt(colMeans(e1^2, na.rm = TRUE))
RMSE_mod2 <- sqrt(colMeans(e2^2, na.rm = TRUE))
RMSE_mod3 <- sqrt(colMeans(e3^2, na.rm = TRUE))
RMSE_mod4 <- sqrt(colMeans(e4^2, na.rm = TRUE))
RMSE_mod5 <- sqrt(colMeans(e5^2, na.rm = TRUE))
#RMSE_mod6 <- sqrt(colMeans(e6^2, na.rm = TRUE))


# Zoom in
plot(1:90, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2500,5000))
lines(1:90, RMSE_mod2, type="l",col=2)
lines(1:90, RMSE_mod3, type="l",col=3)
lines(1:90, RMSE_mod4, type="l",col=4)
lines(1:90, RMSE_mod5, type="l",col=5)
legend("topleft",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_SARIMAX1", "5_SARIMAX2"),col=1:5,lty=1)

# Zoom out
plot(1:90, RMSE_mod1, type="l", col=1, xlab="horizon", ylab="RMSE", ylim = c(2500,7000))
lines(1:90, RMSE_mod2, type="l",col=2)
lines(1:90, RMSE_mod3, type="l",col=3)
lines(1:90, RMSE_mod4, type="l",col=4)
lines(1:90, RMSE_mod5, type="l",col=5)
legend("topleft",legend=c("1_ARIMA1","2_ARIMA2","3_ARIMA3","4_SARIMAX1", "5_SARIMAX2"),col=1:5,lty=1)
```

```{r}
RMSE_mod5
```

**RMSE Medi**

```{r}
mean(RMSE_mod1)
mean(RMSE_mod2)
mean(RMSE_mod3)
mean(RMSE_mod4)
mean(RMSE_mod5)

```
